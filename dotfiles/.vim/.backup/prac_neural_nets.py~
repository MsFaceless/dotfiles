#!/bin/python

import numpy as np

class NeuralNetwork(object):

    def __init__(self, *args, **kwargs):
        self.inputSize = 2
        self.outputSize = 1
        self.hiddenSize = 3

        # weights
        self.w1 = np.random.randn(self.inputSize, self.hiddenSize)
        self.w2 = np.random.randn(self.hiddenSize, self.outputSize)


    def forward(self, x):
        self.z1 = np.dot(x, self.w1) # dot product of input: x and first set of weights
        self.z2 = self.sigmoid(self.z1) # activation function
        self.z3 = np.dot(self.z2, self.w2) # dot product of hidden layer: z2 and second set of weights
        return self.sigmoid(self.z3) # final activation function

    def sigmoid(self, s):
        return 1/(1+np.exp(s))

    def sigmoidPrime(self, s):
        return s * (1 - s)

    def backward(self, x, y, o):
        # backward propogate through the network
        self.oError = y - o
        self.oDelta = self.oError * self.sigmoidPrime(o) # applying derivative of sigmoid to error

        self.z2Error = self.oDelta.dot(self.w2.T) # z2 error: how much the hidden layer contributed
        self.z2Delta = self.z2Error * self.sigmoidPrime(self.z2) # applying derivative of sigmoid to z2 error

        self.w1 += x.T.dot(self.z2Delta) # adjust first set (input --> hidden)
        self.w2 += self.z2.T.dot(self.oDelta) # adjust second set (hidden --> output)

    def train(self, x, y):
        o = self.forward(x)
        self.backward(x, y, o)

    def predict(self, p):
        print('Predicting...')
        print('Input  {0}'.format(p))
        print('Output {0}'.format(self.forward(p)))


if __name__ == "__main__":

    # starting data
    # x = (hours sleeping, hours studying), y = score on test
    x = np.array(([2, 9], [1, 5], [3, 6]), dtype=float)
    y = np.array(([92], [86], [89]), dtype=float)
    xPredicted = np.array(([4, 8]), dtype=float)

    # scale data so everything is between 0 and 100
    x = x/np.amax(x, axis=0)
    y = y/100
    xPredicted = xPredicted/np.amax(xPredicted, axis=0)

    n = NeuralNetwork()
    for i in xrange(100):
        print('\n')
        print('Input     {0}'.format(x))
        print('Actual    {0}'.format(y))
        predicted = n.forward(x)
        print('Predicted {0}'.format(predicted))
        loss = np.mean(np.square(y - predicted))
        #print('Loss      {0}'.format(loss))
        n.train(x, y)
        n.predict(xPredicted)


